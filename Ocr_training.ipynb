{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1ea679-3874-4b66-b5e4-74ca0de763c3",
   "metadata": {},
   "source": [
    "# EasyOcr training Step:\n",
    "- first we have to clone the git repository !git clone https://github.com/JaidedAI/EasyOCR.git\n",
    "- then we have to rename the test.py file to mytest.py file\n",
    "- change the pytorch version with this code %pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "- need to create two folder  'en_train_filtered' and 'en_val' in the \"sagemaker-studiolab-notebooks/EasyOcr_training/EasyOCR/trainer/all_data\"\n",
    "- In 'en_train_filtered' and 'en_val' folders we have provide train and validation data\n",
    "- change the current directry with %cd to /home/studio-lab-user/sagemaker-studiolab-notebooks/EasyOcr_training/EasyOCR/trainer\n",
    "- then pip install -r ../requirements.txt\n",
    "- then !pip install natsort\n",
    "- then !pip install nltk\n",
    "- then copy the code from trainer.py file or used that file\n",
    "- eddit the config_files where we have to mention data path, num_itretion ect ect\n",
    "- then run the last code from trainer.py file\n",
    "- after training the custom train model is going to save in \"sagemaker-studiolab-notebooks/EasyOcr_training/EasyOCR/trainer/saved_models\"\n",
    "- In the \"EasyOCR/trainer/saved_models\" folders there will be two .pth file, in that we have to used \"best_norm_ED.pth\", this is the file which we have to load for our detection\n",
    "- for loading the custom OCR recognition model we have to used this below code:\n",
    "    - here i changed the name as a 'custom_example' for \"best_norm_ED.pth\" file\n",
    "    - #loading custom train recognition easyocr model:\n",
    "    - reader = easyocr.Reader(['en'],gpu = False,user_network_directory='custom_example')\n",
    "- for more imformation please visit https://github.com/JaidedAI/EasyOCR/blob/master/custom_model.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b02d790-af46-4d2d-9d02-f5d2b95c1aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EasyOCR'...\n",
      "remote: Enumerating objects: 2736, done.\u001b[K\n",
      "remote: Counting objects: 100% (1073/1073), done.\u001b[K\n",
      "remote: Compressing objects: 100% (367/367), done.\u001b[K\n",
      "remote: Total 2736 (delta 751), reused 706 (delta 706), pack-reused 1663\u001b[K\n",
      "Receiving objects: 100% (2736/2736), 157.82 MiB | 28.33 MiB/s, done.\n",
      "Resolving deltas: 100% (1678/1678), done.\n",
      "Updating files: 100% (313/313), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/JaidedAI/EasyOCR.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6005235-6108-468a-a0ea-bd440bc9ddab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e607f726-31c9-4539-8b2d-d7b5f5e8eb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.12.0+cu113\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.6 MB)\n",
      "Collecting torchvision==0.13.0+cu113\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n",
      "Collecting torchaudio==0.12.0\n",
      "  Using cached https://download.pytorch.org/whl/rocm5.1.1/torchaudio-0.12.0%2Brocm5.1.1-cp38-cp38-linux_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch==1.12.0+cu113) (4.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (1.24.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (10.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (2023.7.22)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0.post101\n",
      "    Uninstalling torch-2.0.0.post101:\n",
      "      Successfully uninstalled torch-2.0.0.post101\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.2a0+072ec57\n",
      "    Uninstalling torchvision-0.15.2a0+072ec57:\n",
      "      Successfully uninstalled torchvision-0.15.2a0+072ec57\n",
      "Successfully installed torch-1.12.0+cu113 torchaudio-0.12.0+rocm5.1.1 torchvision-0.13.0+cu113\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b7d216-9a74-48da-9d04-70c2148c0161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/sagemaker-studiolab-notebooks/EasyOcr_training'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e59341-687b-4ca3-8f82-680988138aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/EasyOcr_training/EasyOCR/trainer\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/studio-lab-user/sagemaker-studiolab-notebooks/EasyOcr_training/EasyOCR/trainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd4c715-a735-4f44-9d44-ac11a80d8fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/sagemaker-studiolab-notebooks/EasyOcr_training/EasyOCR/trainer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce583fa-dc41-4e2c-a1b3-db526e0747c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r ../requirements.txt (line 1)) (2.0.0.post101)\n",
      "Requirement already satisfied: torchvision>=0.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r ../requirements.txt (line 2)) (0.15.2a0+072ec57)\n",
      "Collecting opencv-python-headless (from -r ../requirements.txt (line 3))\n",
      "  Obtaining dependency information for opencv-python-headless from https://files.pythonhosted.org/packages/71/19/3c65483a80a1d062d46ae20faf5404712d25cb1dfdcaf371efbd67c38544/opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r ../requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r ../requirements.txt (line 5)) (1.24.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r ../requirements.txt (line 6)) (10.0.0)\n",
      "Collecting scikit-image (from -r ../requirements.txt (line 7))\n",
      "  Obtaining dependency information for scikit-image from https://files.pythonhosted.org/packages/33/29/1d696450464d6e13358d3ef185a1fb14a11181c5dab1eb2837c02be86373/scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from -r ../requirements.txt (line 8))\n",
      "  Using cached python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r ../requirements.txt (line 9)) (6.0)\n",
      "Collecting Shapely (from -r ../requirements.txt (line 10))\n",
      "  Obtaining dependency information for Shapely from https://files.pythonhosted.org/packages/d8/41/3db53b03a0f2da266ca9ea35a779b0c4bb34bac06eb2778d4203ce613305/shapely-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached shapely-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from -r ../requirements.txt (line 11))\n",
      "  Obtaining dependency information for pyclipper from https://files.pythonhosted.org/packages/6d/2f/18c46f5c8f985426dbb4ffe94901150937986fe779a0eacb81cf4bc397b3/pyclipper-1.3.0.post5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata\n",
      "  Using cached pyclipper-1.3.0.post5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from -r ../requirements.txt (line 12))\n",
      "  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/6d/92/8d7aebd4430ab5ff65df2bfee6d5745f95c004284db2d8ca76dcbfd9de47/ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->-r ../requirements.txt (line 1)) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->-r ../requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->-r ../requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->-r ../requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->-r ../requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torchvision>=0.5->-r ../requirements.txt (line 2)) (2.31.0)\n",
      "Collecting imageio>=2.27 (from scikit-image->-r ../requirements.txt (line 7))\n",
      "  Obtaining dependency information for imageio>=2.27 from https://files.pythonhosted.org/packages/c0/69/3aaa69cb0748e33e644fda114c9abd3186ce369edd4fca11107e9f39c6a7/imageio-2.33.1-py3-none-any.whl.metadata\n",
      "  Using cached imageio-2.33.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->-r ../requirements.txt (line 7))\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/06/a3/68d17088a4f09565bc7341fd20490da8191ec4cddde479daaabbe07bb603/tifffile-2023.7.10-py3-none-any.whl.metadata\n",
      "  Using cached tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image->-r ../requirements.txt (line 7))\n",
      "  Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->-r ../requirements.txt (line 7)) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image->-r ../requirements.txt (line 7))\n",
      "  Obtaining dependency information for lazy_loader>=0.2 from https://files.pythonhosted.org/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl.metadata\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from python-bidi->-r ../requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from jinja2->torch->-r ../requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision>=0.5->-r ../requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision>=0.5->-r ../requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision>=0.5->-r ../requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->torchvision>=0.5->-r ../requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from sympy->torch->-r ../requirements.txt (line 1)) (1.3.0)\n",
      "Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
      "Using cached shapely-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached pyclipper-1.3.0.post5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (682 kB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Using cached imageio-2.33.1-py3-none-any.whl (313 kB)\n",
      "Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Using cached tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "Installing collected packages: pyclipper, ninja, tifffile, Shapely, PyWavelets, python-bidi, opencv-python-headless, lazy_loader, imageio, scikit-image\n",
      "Successfully installed PyWavelets-1.4.1 Shapely-2.0.2 imageio-2.33.1 lazy_loader-0.3 ninja-1.11.1.1 opencv-python-headless-4.9.0.80 pyclipper-1.3.0.post5 python-bidi-0.4.2 scikit-image-0.21.0 tifffile-2023.7.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37aa007d-de4c-452f-a9fa-c4e416a89d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natsort\n",
      "  Obtaining dependency information for natsort from https://files.pythonhosted.org/packages/ef/82/7a9d0550484a62c6da82858ee9419f3dd1ccc9aa1c26a1e43da3ecd20b0d/natsort-8.4.0-py3-none-any.whl.metadata\n",
      "  Using cached natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ca960e-d65a-46c3-b697-7a4665d070e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nltk) (1.3.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/eb/10/4ccc8eed80f11c082a2883d49d4090aa80c7f65704216a529f490cb089b1/regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nltk) (4.65.0)\n",
      "Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d875f20-80df-4d57-8e32-418c3f440971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827d36d9-6d5b-44af-bace-8277cf3c6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2257b779-c8f6-43b6-b54a-880ea0df0d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c72d52-fd9b-4e68-80bd-4cf61acae638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data\n",
      "opt.select_data: ['en_train_filtered']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data\t dataset: en_train_filtered\n",
      "all_data/en_train_filtered\n",
      "sub-directory:\t/en_train_filtered\t num samples: 6479\n",
      "num total samples of en_train_filtered: 6479 x 1.0 (total_data_usage_ratio) = 6479\n",
      "num samples of en_train_filtered per batch: 32 x 1.0 (batch_ratio) = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 32 = 32\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/en_val\t dataset: /\n",
      "all_data/en_val/\n",
      "sub-directory:\t/.\t num samples: 717\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input parameters 64 600 20 1 256 256 97 34 None ResNet BiLSTM CTC\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "      (ConvNet): ResNet(\n",
      "        (conv0_1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv0_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv4_1): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "        (bn4_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv4_2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (bn4_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=256, out_features=97, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.conv0_1.weight 144\n",
      "module.FeatureExtraction.ConvNet.bn0_1.weight 16\n",
      "module.FeatureExtraction.ConvNet.bn0_1.bias 16\n",
      "module.FeatureExtraction.ConvNet.conv0_2.weight 4608\n",
      "module.FeatureExtraction.ConvNet.bn0_2.weight 32\n",
      "module.FeatureExtraction.ConvNet.bn0_2.bias 32\n",
      "module.FeatureExtraction.ConvNet.layer1.0.conv1.weight 18432\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn1.weight 64\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn1.bias 64\n",
      "module.FeatureExtraction.ConvNet.layer1.0.conv2.weight 36864\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn2.weight 64\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn2.bias 64\n",
      "module.FeatureExtraction.ConvNet.layer1.0.downsample.0.weight 2048\n",
      "module.FeatureExtraction.ConvNet.layer1.0.downsample.1.weight 64\n",
      "module.FeatureExtraction.ConvNet.layer1.0.downsample.1.bias 64\n",
      "module.FeatureExtraction.ConvNet.conv1.weight 36864\n",
      "module.FeatureExtraction.ConvNet.bn1.weight 64\n",
      "module.FeatureExtraction.ConvNet.bn1.bias 64\n",
      "module.FeatureExtraction.ConvNet.layer2.0.conv1.weight 73728\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn1.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn1.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer2.0.conv2.weight 147456\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn2.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn2.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer2.0.downsample.0.weight 8192\n",
      "module.FeatureExtraction.ConvNet.layer2.0.downsample.1.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer2.0.downsample.1.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer2.1.conv1.weight 147456\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn1.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn1.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer2.1.conv2.weight 147456\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn2.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn2.bias 128\n",
      "module.FeatureExtraction.ConvNet.conv2.weight 147456\n",
      "module.FeatureExtraction.ConvNet.bn2.weight 128\n",
      "module.FeatureExtraction.ConvNet.bn2.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer3.0.conv1.weight 294912\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.0.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.0.downsample.0.weight 32768\n",
      "module.FeatureExtraction.ConvNet.layer3.0.downsample.1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.0.downsample.1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.1.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.1.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.2.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.2.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.3.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.3.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.4.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.4.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.conv3.weight 589824\n",
      "module.FeatureExtraction.ConvNet.bn3.weight 256\n",
      "module.FeatureExtraction.ConvNet.bn3.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer4.0.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer4.0.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer4.1.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer4.1.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer4.2.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer4.2.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.conv4_1.weight 262144\n",
      "module.FeatureExtraction.ConvNet.bn4_1.weight 256\n",
      "module.FeatureExtraction.ConvNet.bn4_1.bias 256\n",
      "module.FeatureExtraction.ConvNet.conv4_2.weight 262144\n",
      "module.FeatureExtraction.ConvNet.bn4_2.weight 256\n",
      "module.FeatureExtraction.ConvNet.bn4_2.bias 256\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.0.linear.weight 131072\n",
      "module.SequenceModeling.0.linear.bias 256\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.1.linear.weight 131072\n",
      "module.SequenceModeling.1.linear.bias 256\n",
      "module.Prediction.weight 24832\n",
      "module.Prediction.bias 97\n",
      "Total Trainable Params: 13465169\n",
      "Trainable params num :  13465169\n",
      "Optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: 0123456789\n",
      "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €\n",
      "lang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "experiment_name: en_filtered\n",
      "train_data: all_data\n",
      "valid_data: all_data/en_val\n",
      "manualSeed: 1111\n",
      "workers: 6\n",
      "batch_size: 32\n",
      "num_iter: 3000\n",
      "valInterval: 500\n",
      "saved_model: \n",
      "FT: False\n",
      "optim: adam\n",
      "lr: 0.01.\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['en_train_filtered']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 34\n",
      "imgH: 64\n",
      "imgW: 600\n",
      "rgb: False\n",
      "contrast_adjust: 0.0\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: ResNet\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 256\n",
      "hidden_size: 256\n",
      "decode: greedy\n",
      "new_prediction: False\n",
      "freeze_FeatureFxtraction: False\n",
      "freeze_SequenceModeling: False\n",
      "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "num_class: 97\n",
      "---------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "opt = get_config(\"config_files/en_filtered_config.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f6bebee-7273-45c4-a6b8-4e50c200e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is check for any cache files:\n",
    "import os\n",
    "for elements in os.listdir(os.path.join(os.getcwd(),\"all_data\",\"en_train_filtered\")):\n",
    "    if elements==\".ipynb_checkpoints\":\n",
    "        # os.rmdir(os.path.join(\"all_data\",\"en_train_filtered\",\".ipynb_checkpoints\"))\n",
    "        print(\"gotcha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f04489df-a7e4-4195-acda-86a566fd57c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if there is any cache file this code will remove it but need to mention the file path accordingly:\n",
    "path=os.path.join(\"all_data\",\"en_train_filtered\",\".ipynb_checkpoints\")\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e61504-4d64-49d4-aa66-48520cfcc64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
