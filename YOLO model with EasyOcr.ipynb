{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e76ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import easyocr\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff85cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "#loading custom train recognition easyocr model:\n",
    "reader = easyocr.Reader(['en'],gpu = False,user_network_directory='custom_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115f1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb33db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_image:(667, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "#load the image:\n",
    "img =cv2.imread(\"img.jpg\")\n",
    "image = img.copy()\n",
    "print(f'original_image:{image.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea34b9d",
   "metadata": {},
   "source": [
    "### setting up Hsv colour range for white and blue colour :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d7bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HSV color ranges for white\n",
    "white_lower = np.array([0,0,215])\n",
    "white_upper = np.array([180,255,255]) # (These ranges will detect white)\n",
    "\n",
    "# Define the HSV color ranges for deep blue\n",
    "lower_deep_blue = np.array([100, 50, 50])\n",
    "upper_deep_blue = np.array([140, 255, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e6e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 184.5ms\n",
      "Speed: 4.0ms preprocess, 184.5ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "result = model.predict(source=image,save = True,save_crop = True)\n",
    "model.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0112638",
   "metadata": {},
   "source": [
    "### Applying Non Maximam Supression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4fd4743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "cordinat = []\n",
    "confe = []\n",
    "\n",
    "    \n",
    "for r in (result):\n",
    "    boxes = r.boxes.cpu().numpy() \n",
    "    detection = boxes\n",
    "    for i in range(len(detection)):\n",
    "        \n",
    "        row = detection[i]\n",
    "        conf = row.conf\n",
    "        if conf > 0.4:\n",
    "            track_id = row.id\n",
    "            \n",
    "            xyxys =row.xyxy\n",
    "            \n",
    "            for xyxy in xyxys:\n",
    "                x1 = int(xyxy[0])\n",
    "                y1 = int(xyxy[1])\n",
    "                x2 = int(xyxy[2])\n",
    "                y2 = int(xyxy[3])\n",
    "                box = np.array([x1,y1,x2,y2])\n",
    "                \n",
    "                cordinat.append(box)\n",
    "                confe.append(float(conf))\n",
    "                \n",
    "#clean:\n",
    "boxes_np =np.array(cordinat).tolist()\n",
    "confidences_np = np.array(confe).tolist()\n",
    "\n",
    "#now applying the non maximum Supression:\n",
    "index = cv2.dnn.NMSBoxes(boxes_np,confidences_np, 0.25,0.7).flatten()\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d5928",
   "metadata": {},
   "source": [
    "### Now we have to crop all detecting objects with the help of the index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0ea125",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop =[]\n",
    "\n",
    "for ind in index:\n",
    "    #extract bounding box:\n",
    "    x1,y1,x2,y2 = boxes_np[ind]\n",
    "    roi = image[y1:y2,x1:x2]\n",
    "    crop.append(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3213c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jersey_number:12 \n",
      "prob:0.9934331108154081\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(crop)):\n",
    "    img_2 = crop[i]\n",
    "    # print(f'original_image:{img_2.shape}')\n",
    "\n",
    "    #Convert the image to a floating-point representation\n",
    "    img_float = img_2.astype(np.float32) / 255.0\n",
    "\n",
    "    # Increase contrast (you can experiment with the values)\n",
    "    alpha = 1\n",
    "    enhanced_img = cv2.multiply(img_float, alpha)\n",
    "\n",
    "    # Increase brightness (you can experiment with the values)\n",
    "    beta = 3\n",
    "    enhanced_img = cv2.add(enhanced_img, beta / 255.0)\n",
    "\n",
    "    # Clip the values to the valid range [0, 1]\n",
    "    enhanced_img = np.clip(enhanced_img, 0, 1)\n",
    "\n",
    "    # Convert back to uint8 for display\n",
    "    enhanced_img = (enhanced_img * 255).astype(np.uint8)\n",
    "\n",
    "    # print(f'enhanced_img:{enhanced_img.shape}')\n",
    "\n",
    "    # Resize the image to a larger size (e.g., 2x)\n",
    "    resize_factor = 2\n",
    "    resized_image = cv2.resize(enhanced_img, (enhanced_img.shape[1]*resize_factor, enhanced_img.shape[0]*resize_factor))\n",
    "\n",
    "    # Apply sharpening to the resized image\n",
    "    kernel = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])  # Sharpening kernel\n",
    "    sharpened_image = cv2.filter2D(resized_image, -1, kernel)\n",
    "\n",
    "    # print(f'sharpened_image:{sharpened_image.shape}')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    hsv_img = cv2.cvtColor(img_2, cv2.COLOR_BGR2HSV)\n",
    "    blurred_image = cv2.bilateralFilter(hsv_img, d=9, sigmaColor=80, sigmaSpace=75)\n",
    "    \n",
    "    # Masking the image to find our color\n",
    "    mask_white = cv2.inRange(blurred_image, white_lower,white_upper)\n",
    "    mask_deep_blue = cv2.inRange(blurred_image, lower_deep_blue, upper_deep_blue)\n",
    "    \n",
    "    #gtting pixcel for white color:\n",
    "    pixel_count_w = cv2.countNonZero(mask_white)\n",
    "    #gtting pixcel for blue color:\n",
    "    pixel_count_b = cv2.countNonZero(mask_deep_blue)\n",
    "    \n",
    "                \n",
    "    if pixel_count_w > pixel_count_b  :\n",
    "        \n",
    "        box = boxes_np[i]\n",
    "        x1, y1, x2,y2 = box\n",
    "        out = cv2.rectangle(image, (x1, y1), (x2 , y2), (0, 255, 0), 2) #drawing rectangle\n",
    "        \n",
    "        img_gray = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        results = reader.readtext(img_gray,allowlist= '0123456789')\n",
    "\n",
    "        for (bbox, text, prob) in results:\n",
    "            if prob > 0.4:\n",
    "                if  len(text) == 2:\n",
    "                    # print(f'jersey_number:{text} \\nbbox:{bbox} \\nprob:{prob}')\n",
    "                    cv2.putText(image,text,(x1,y1-10),cv2.FONT_HERSHEY_COMPLEX,0.7,(255,255,255),2)\n",
    "                    jersey_number = text\n",
    "                    print( f'jersey_number:{jersey_number} \\nprob:{prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ee2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the modified image to a new file\n",
    "cv2.imwrite('output_image.jpg', image)\n",
    "\n",
    "# showing the output_image:\n",
    "cv2.imshow(\"img\",out)\n",
    "cv2.waitKey(0) == 27\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
